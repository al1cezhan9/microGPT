{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1fd8675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read into text\n",
    "with open('input.txt', 'r', encoding='utf-8') as f:\n",
    "  text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7e9a952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n",
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(vocab_size)\n",
    "print(''.join(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4fdb4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map char (str) to integer by index in the chars list\n",
    "# ambigous ordering, losing a data dimension in proximity?\n",
    "# tradeoff between size of vocab and dimension of embedding\n",
    "ctoi = {ch:i for i,ch in enumerate(chars)}\n",
    "itoc = {i:ch for i,ch in enumerate(chars)}\n",
    "# lambda = mini functions\n",
    "encode = lambda s: [ctoi[c] for c in s]\n",
    "decode = lambda l: ''.join([itoc[i] for i in l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1adb1fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode entire dataset\n",
    "# store in torch.Tensor (multi-d array optimized for computation)\n",
    "import torch\n",
    "# torch.long = 64-bit integers (cannot use floats for certain downstream ops)\n",
    "# tensor = array w/ autograd, gpu accel, vectorized/parallelized\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91d9487e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into 90% train vs. 10% validation\n",
    "# no shuffle! since order matters\n",
    "n = int(0.9*len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15798e4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only train transformer on chunks of max length = block_size\n",
    "block_size = 8\n",
    "train_data[:block_size+1]\n",
    "# the +1 accounts for how 9 integers contain 8 \"examples\" of input-output pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a8996cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: tensor([18]), Target: 47\n",
      "Input: tensor([18, 47]), Target: 56\n",
      "Input: tensor([18, 47, 56]), Target: 57\n",
      "Input: tensor([18, 47, 56, 57]), Target: 58\n",
      "Input: tensor([18, 47, 56, 57, 58]), Target: 1\n",
      "Input: tensor([18, 47, 56, 57, 58,  1]), Target: 15\n",
      "Input: tensor([18, 47, 56, 57, 58,  1, 15]), Target: 47\n",
      "Input: tensor([18, 47, 56, 57, 58,  1, 15, 47]), Target: 58\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:block_size] # all the training data, not always all used\n",
    "y = train_data[1:block_size+1] # offset by 1, targets for each position, outputs for each \"example\"\n",
    "for t in range(block_size):\n",
    "  context = x[:t+1] # context window increases\n",
    "  target = y[t]\n",
    "  print(f\"Input: {context}, Target: {target}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2c0ac2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack up blocks so GPU can process in parallel\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "batch_size = 4 # num independent sequences processed in parallel\n",
    "block_size = 8 # max context length for predictions\n",
    "# context size isn't constant (it's a max) to juice out the max examples\n",
    "# causal masking = preventing attention to future tokens\n",
    "# also helps the model infer when context provided < max\n",
    "# autoregressive framework\n",
    "# this is called prefix training & it's free with causal masking\n",
    "\n",
    "def get_batch(split):\n",
    "  # generate small batch of data (input & output)\n",
    "  data = train_data if split == 'train' else val_data\n",
    "  # get random position (-block_size) to account for valid starting positions\n",
    "  # get {batch_size} number of these random offsets\n",
    "  ix = torch.randint(len(data)-block_size, (batch_size,))\n",
    "  # torch.stack stacks up into rows of 4x8 tensor\n",
    "  # 32 examples, x and y just hold the end points\n",
    "  x = torch.stack([data[i:i+block_size] for i in ix]) # row = context block\n",
    "  y = torch.stack([data[i+1:i+block_size+1] for i in ix]) # x shifted by 1\n",
    "  return x,y\n",
    "\n",
    "xb, yb = get_batch('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57fcb232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: [24], target: 43\n",
      "input: [24, 43], target: 58\n",
      "input: [24, 43, 58], target: 5\n",
      "input: [24, 43, 58, 5], target: 57\n",
      "input: [24, 43, 58, 5, 57], target: 1\n",
      "input: [24, 43, 58, 5, 57, 1], target: 46\n",
      "input: [24, 43, 58, 5, 57, 1, 46], target: 43\n",
      "input: [24, 43, 58, 5, 57, 1, 46, 43], target: 39\n",
      "input: [44], target: 53\n",
      "input: [44, 53], target: 56\n",
      "input: [44, 53, 56], target: 1\n",
      "input: [44, 53, 56, 1], target: 58\n",
      "input: [44, 53, 56, 1, 58], target: 46\n",
      "input: [44, 53, 56, 1, 58, 46], target: 39\n",
      "input: [44, 53, 56, 1, 58, 46, 39], target: 58\n",
      "input: [44, 53, 56, 1, 58, 46, 39, 58], target: 1\n",
      "input: [52], target: 58\n",
      "input: [52, 58], target: 1\n",
      "input: [52, 58, 1], target: 58\n",
      "input: [52, 58, 1, 58], target: 46\n",
      "input: [52, 58, 1, 58, 46], target: 39\n",
      "input: [52, 58, 1, 58, 46, 39], target: 58\n",
      "input: [52, 58, 1, 58, 46, 39, 58], target: 1\n",
      "input: [52, 58, 1, 58, 46, 39, 58, 1], target: 46\n",
      "input: [25], target: 17\n",
      "input: [25, 17], target: 27\n",
      "input: [25, 17, 27], target: 10\n",
      "input: [25, 17, 27, 10], target: 0\n",
      "input: [25, 17, 27, 10, 0], target: 21\n",
      "input: [25, 17, 27, 10, 0, 21], target: 1\n",
      "input: [25, 17, 27, 10, 0, 21, 1], target: 54\n",
      "input: [25, 17, 27, 10, 0, 21, 1, 54], target: 39\n"
     ]
    }
   ],
   "source": [
    "# this gets the actual full examples\n",
    "for b in range(batch_size): # batch dimension\n",
    "  for t in range(block_size): # time dimension\n",
    "    context = xb[b, :t+1]\n",
    "    target = yb[b, t] # will be used for loss function later on\n",
    "    print(f\"input: {context.tolist()}, target: {target}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a7693a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.8786, grad_fn=<NllLossBackward0>)\n",
      "\n",
      "SKIcLT;AcELMoTbvZv C?nq-QE33:CJqkOKH-q;:la!oiywkHjgChzbQ?u!3bLIgwevmyFJGUGp\n",
      "wnYWmnxKWWev-tDqXErVKLgJt-wBpm&yiltNCjeO3:Cx&vvMYW-txjuAd IRFbTpJ$zkZelxZtTlHNzdXXUiQQY:qFINTOBNLI,&oTigq z.c:Cq,SDXzetn3XVj\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "n_embd = 32\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    # learnable embedding table = matrix lookup table (vocab_size, vocab_size)\n",
    "    # row i = logits/unnormalized scores/prob distr for next token given curr token = i\n",
    "    # param 1 = num_embeddings (# unique tok in vocab)\n",
    "    # param 2 = embedding_dim (size of vec representing a token)\n",
    "    # usually embedding_dim < num_embeddings, but we have small vocab \n",
    "    # self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    # decompose \n",
    "    self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "    # positional encoding\n",
    "    self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
    "\n",
    "    # go to token embed -> logits\n",
    "    self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "\n",
    "  def forward(self, idx, targets=None):\n",
    "    B,T=idx.shape\n",
    "    # idx and targets are both (B,T) tensor\n",
    "    tok_embd = self.token_embedding_table(idx) # (B,T,n_embd)\n",
    "    pos_embd = self.position_embedding_table(torch.arange(T)) # (T,n_embd)\n",
    "    x = tok_embd + pos_embd # (B,T,C), addition works nicely\n",
    "    # now x hold token identities & positions\n",
    "    logits = self.lm_head(x) # (B,T,vocab_size) \n",
    "\n",
    "    if targets is None:\n",
    "        loss = None\n",
    "    else:\n",
    "        # use built-in -log likelihood loss\n",
    "        # pytorch wants C as second dim \n",
    "        # stretch out into 2D \n",
    "        B, T, C = logits.shape\n",
    "        logits = logits.view(B*T, C)\n",
    "        targets = targets.view(B*T)\n",
    "        loss = F.cross_entropy(logits, targets)\n",
    "    return logits, loss\n",
    "  def generate(self, idx, max_new_tokens):\n",
    "    # max_new_tokens = how many new tokens we want to generate\n",
    "    # idx = (B, T) array of indices rn\n",
    "    for _ in range(max_new_tokens):\n",
    "      # get ALL predictions\n",
    "      logits, loss = self(idx)\n",
    "      # model predicts logits for every position, we only care about next token\n",
    "      # take only the last time step prediction\n",
    "      logits = logits[:, -1, :] # becomes (B, C)\n",
    "      # apply softmax: logits -> probabilities\n",
    "      probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "      # sample from distribution to get next token\n",
    "      idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "      # append sampled index to running sequence\n",
    "      idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "    return idx\n",
    "m = BigramLanguageModel()\n",
    "logits, loss = m(xb, yb)\n",
    "print(loss)\n",
    "\n",
    "# 1x1 tensor holding a 0, kickoff character\n",
    "idx = torch.zeros((1, 1), dtype=torch.long)\n",
    "print(decode(m.generate(idx, max_new_tokens=200)[0].tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aaccd734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup before we train\n",
    "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)\n",
    "# m.parameters() returns iterator over all knobs to tune (embedding matrices, biases, weights etd)\n",
    "# each param has .data tensor & .grad tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ef2f4a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\n",
      "Loss: 2.5512022972106934\n",
      "Perplexity: 12.822510987982028\n",
      "====\n",
      "Iteration: 1000\n",
      "Loss: 2.4487292766571045\n",
      "Perplexity: 11.573630488650798\n",
      "====\n",
      "Iteration: 2000\n",
      "Loss: 2.4547176361083984\n",
      "Perplexity: 11.64314548081702\n",
      "====\n",
      "Iteration: 3000\n",
      "Loss: 2.453296184539795\n",
      "Perplexity: 11.62660707046919\n",
      "====\n",
      "Iteration: 4000\n",
      "Loss: 2.3911964893341064\n",
      "Perplexity: 10.926559637065708\n",
      "====\n",
      "Iteration: 5000\n",
      "Loss: 2.476576328277588\n",
      "Perplexity: 11.900451353664693\n",
      "====\n",
      "Iteration: 6000\n",
      "Loss: 2.4607365131378174\n",
      "Perplexity: 11.713435462882147\n",
      "====\n",
      "Iteration: 7000\n",
      "Loss: 2.3521885871887207\n",
      "Perplexity: 10.508543439111865\n",
      "====\n",
      "Iteration: 8000\n",
      "Loss: 2.375598669052124\n",
      "Perplexity: 10.757451411940833\n",
      "====\n",
      "Iteration: 9000\n",
      "Loss: 2.336932420730591\n",
      "Perplexity: 10.34944009069425\n",
      "====\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32 # increased from before\n",
    "block_size = 8\n",
    "n_iter = 10000\n",
    "import math\n",
    "# lol lowk just keep running this\n",
    "for steps in range(n_iter):\n",
    "  # sample a new batch of data\n",
    "  xb, yb = get_batch('train')\n",
    "  # eval the loss\n",
    "  logits, loss = m(xb, yb)\n",
    "  optimizer.zero_grad(set_to_none=True) # zero out gradients!!!\n",
    "  loss.backward() # get grads for all params\n",
    "  optimizer.step() # using grad to update params\n",
    "  if steps%1000 == 0:\n",
    "    print(\"Iteration: \" + str(steps))\n",
    "    print(\"Loss: \" + str(loss.item()))\n",
    "    # on average, the model is choosing among *perplexity* plausible next tokens\n",
    "    # since vocab size = 65, random guessing = ln(65)~4\n",
    "    print(\"Perplexity: \" + str(math.exp(loss.item())))\n",
    "    print(\"====\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b5c13f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "IOr with is aras Tht; thap\n",
      "YORENGind hathinthethasiouro oulof I and s l SS:\n",
      "Iffof; hat t-aroresere and; s fover;\n",
      "\n",
      "AUMENGHALA:\n",
      "A:\n",
      "This;\n",
      "I t.\n",
      "NAn thal\n",
      "Fiotha her owa\n",
      "Fouidif toury aris ior yoress ane hit in,\n",
      "O:\n",
      "LETAUns.\n",
      "Isat t  st far thas s sthasers t Bokerdace\n",
      "My e\n",
      "TENIris,\n",
      "G oue, hon buime.\n",
      "adive momo, warawoofe, M: atre deseeshen tar me ifukeshaceweag t io, d at.\n",
      "KE: co ctisefang he t veswerde, t thises;\n",
      "Bund wiemetiarele hen\n",
      "le, be ad, jush we, withindire INENGRe' thovexpu a PESAn stlis wilur\n"
     ]
    }
   ],
   "source": [
    "# check out improvements to predictions after training\n",
    "idx = torch.zeros((1, 1), dtype=torch.long)\n",
    "print(decode(m.generate(idx, max_new_tokens=500)[0].tolist()))\n",
    "# tokens still not talking to each other!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6584867",
   "metadata": {},
   "source": [
    "### some clever math..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "25c4d62c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# toy example\n",
    "torch.manual_seed(1089)\n",
    "B,T,C=4,8,2 # batch time channels\n",
    "x=torch.randn(B,T,C)\n",
    "x.shape\n",
    "\n",
    "# we want the 8 tokens to talk to each other\n",
    "# info should only flow from past -> present not vice versa\n",
    "# let's give the t-th tok the average of all toks preceding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "154fc481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bag of words\n",
    "# VERSION 1 [naive]\n",
    "# we want x[b,t]=mean{x[b,i] where i<t}\n",
    "xbow1 = torch.zeros((B,T,C))\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = x[b,:t+1] # slice up to t -> (t,C)\n",
    "        xbow1[b,t] = torch.mean(xprev,0)\n",
    "# this works but is inefficient!\n",
    "# matrix multiplication!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "770ca48a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
      "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
      "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# VERSION 2 [matmul]\n",
    "# lower triangular ones matrix\n",
    "wei = torch.tril(torch.ones((T,T)))\n",
    "# weighted sums \n",
    "wei = wei / wei.sum(1,keepdim=True)\n",
    "# (B,T,T) @ (B,T,C) ----> (B,T,C)\n",
    "xbow2 = wei @ x # batch multiply\n",
    "print(wei)\n",
    "torch.allclose(xbow1, xbow2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f284eb00",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
      "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
      "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# VERSION 3 [softmax]\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "wei = torch.zeros((T,T)) # begin @ 0\n",
    "# make all elements where tril = 0 -> -inf \n",
    "# past cannot see the future\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "print(wei)\n",
    "xbow3 = wei @ x\n",
    "torch.allclose(xbow1, xbow3)\n",
    "# we will use this one because we can learn the affinities!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c912bde4",
   "metadata": {},
   "source": [
    "### self-attention!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910b90e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1337)\n",
    "B,T,C = 4,8,32\n",
    "x = torch.randn(B,T,C)\n",
    "\n",
    "# single head of self attention\n",
    "head_size = 16\n",
    "key = nn.Linear(C, head_size, bias=False)\n",
    "query = nn.Linear(C, head_size, bias=False)\n",
    "value = nn.Linear(C, head_size, bias=False)\n",
    "\n",
    "k=key(x) # (B,T,16)\n",
    "q=query(x) # (B,T,16)\n",
    "wei=k @ q.transpose(-2, -1) # (B,T,16) x (B,16,T) = (B,T,T)\n",
    " \n",
    "tril = torch.tril(torch.ones(T,T)) # get rid of this to unmask for encoder\n",
    "# wei = torch.zeros((T,T))\n",
    "wei = wei.masked_fill(tril==0, float('-inf'))\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "\n",
    "v=value(x)\n",
    "out = wei @ v\n",
    "# out = wei @ x\n",
    "\n",
    "# elements across batch dimensions never talk to each other\n",
    "# no notion of space... yet\n",
    "# \"self\" means KV and Q are produced from same tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ab9cb501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.5877, 0.4123, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.4457, 0.2810, 0.2733, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2220, 0.7496, 0.0175, 0.0109, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0379, 0.0124, 0.0412, 0.0630, 0.8454, 0.0000, 0.0000, 0.0000],\n",
       "         [0.5497, 0.2187, 0.0185, 0.0239, 0.1831, 0.0062, 0.0000, 0.0000],\n",
       "         [0.2576, 0.0830, 0.0946, 0.0241, 0.1273, 0.3627, 0.0507, 0.0000],\n",
       "         [0.0499, 0.1052, 0.0302, 0.0281, 0.1980, 0.2657, 0.1755, 0.1474]],\n",
       "\n",
       "        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.4289, 0.5711, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.5413, 0.1423, 0.3165, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0635, 0.8138, 0.0557, 0.0669, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.4958, 0.0758, 0.2224, 0.0156, 0.1905, 0.0000, 0.0000, 0.0000],\n",
       "         [0.3957, 0.1127, 0.3724, 0.0024, 0.1128, 0.0040, 0.0000, 0.0000],\n",
       "         [0.0229, 0.5252, 0.0084, 0.0047, 0.2768, 0.0983, 0.0637, 0.0000],\n",
       "         [0.0021, 0.0327, 0.0042, 0.0821, 0.0244, 0.8253, 0.0154, 0.0139]],\n",
       "\n",
       "        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.5842, 0.4158, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.5148, 0.3227, 0.1624, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1818, 0.0991, 0.6131, 0.1060, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.4658, 0.0065, 0.0221, 0.4951, 0.0105, 0.0000, 0.0000, 0.0000],\n",
       "         [0.5680, 0.0253, 0.0580, 0.1483, 0.0664, 0.1339, 0.0000, 0.0000],\n",
       "         [0.4906, 0.0256, 0.0375, 0.0027, 0.3457, 0.0177, 0.0802, 0.0000],\n",
       "         [0.0167, 0.0192, 0.2619, 0.0270, 0.0554, 0.0856, 0.4455, 0.0886]],\n",
       "\n",
       "        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.7831, 0.2169, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0058, 0.9929, 0.0013, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.3320, 0.4751, 0.1769, 0.0160, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0814, 0.1088, 0.5362, 0.2061, 0.0674, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1960, 0.1972, 0.1274, 0.1287, 0.2556, 0.0951, 0.0000, 0.0000],\n",
       "         [0.0356, 0.0119, 0.1669, 0.2186, 0.0318, 0.5158, 0.0195, 0.0000],\n",
       "         [0.0101, 0.0368, 0.0097, 0.0414, 0.3430, 0.1230, 0.0089, 0.4272]]],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keep wei diffuse before softmaxxing\n",
    "# otherwise will converge to one-hot\n",
    "wei "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f504e093",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894566ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
